"""HidrologyReport"""

import warnings
import struct
from typing import Tuple, List, Optional, Any
from functools import partial
from datetime import datetime
from dateutil.relativedelta import relativedelta

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import geopandas as gpd

from azure.identity import DefaultAzureCredential
import pyodbc

import contextily as cx

from scipy import stats

from adjustText import adjust_text
from pretty_html_table import build_table
from jinja2 import Environment, FileSystemLoader

from flood_finder.urban_areas import UrbanAreas

from .multiprocessing import Parallel, ExecutionType
from .otto import Otto
from .utils import disable_warnings, fig2base64, timestamp_date


class HydrologyReport:
    """Main class for the hydrology report"""

    columns_rename = {
        "codigo": "Código",
        "rio": "Rio",
        "nuareamont": "Área mont. (km²)",
        "anoini": "Ano Ini",
        "anofim": "Ano Fim",
        "period": "Período (anos)",
        "emoper": "Operando",
    }

    # list of distributions to adjust
    default_distrs = ["gumbel_r", "lognorm"]

    # specify hydrologycal year for some states
    # default is from october-september
    hydrological_year = {"RS": 1, "default": 10}

    def __init__(
        self,
        urban_areas_path: str,
        municipalities_path: str,
        reaches_path: str,
        watersheds_path: str,
        stations_path: str,
        disasters_path: Optional[str] = None,
        crs: str = "epsg:4674",
    ):
        self.reaches = self.watersheds = None
        self.uas = self.ua = self.muns = self.mun = None
        self.stations = self.conn = self.disasters = None
        self.data = {}
        self.crs = crs

        self._connect_datalake()
        disable_warnings()

        # to speed up initialization, we are going to use Threads
        self.futures = []
        with Parallel(ExecutionType.THREAD) as executor, warnings.catch_warnings():

            # Suppressing warnings
            warnings.simplefilter("ignore")

            # load the urban areas and municipalities
            executor.timed_submit(self._load_urban_area, urban_areas_path, crs)
            executor.timed_submit(self._load_municipalities, municipalities_path, crs)

            # Read the River Reaches database
            executor.timed_submit(self._load_reaches, reaches_path, crs)

            # read the watersheds
            executor.timed_submit(self._load_watersheds, watersheds_path, crs)

            # read the stations
            executor.timed_submit(self._load_stations, stations_path, crs)

            # read the disasters (if applicable)
            if disasters_path is not None:
                executor.timed_submit(self._load_disasters, disasters_path)

    ###### Selected Stations ######
    @property
    def selected_stations(self):
        """Return the stations that have been selected, regardless the position

        Returns:
            List: list of stations code in integer
        """
        stations = []
        for position in ["up", "down"]:
            name = f"selected_{position}_stations"
            if name in self.data and len(self.data[name]) > 0:
                aux = self.data[name]["codigo"].astype("int")
                stations = stations + aux.to_list()

        return stations

    ###### Static Methods ######
    @staticmethod
    def get_hydrological_year(dt: pd.DatetimeIndex, month: int = 10) -> str:
        """Get the hydrological year as a string

        Args:
            dt (DatetimeIndex): Datetime of the measurement

        Returns:
            str: Hydrological year
        """

        # if dt.month >= month:
        #     s = f"{dt.year}/{dt.year + 1}"
        # else:
        #     s = f"{dt.year - 1}/{dt.year}"

        # return s
        df = pd.DataFrame(index=dt)
        df["position"] = df.index.month >= month
        df.loc[df["position"], "ref"] = df.loc[df["position"]].index.year
        df.loc[~df["position"], "ref"] = df.loc[~df["position"]].index.year - 1
        df["ref"] = df["ref"].astype("int")
        df["hydro_year"] = df["ref"].astype("str") + "/" + (df["ref"] + 1).astype("str")

        return df.set_index("hydro_year").index

    @staticmethod
    def recurring_time(Q, distr, *params) -> float:  # pylint: disable=C0103
        """Calculate the return time of a value, given a
        distribution and its parameters.

        Args:
            Q (float): Value (Discharge)
            distr (scipy.distribution): The distribution object

        Returns:
            float: Recurring time
        """
        prob = 1 - distr.cdf(Q, *params)
        return 1 / prob

    ###### Private INIT Functions ######
    def _connect_datalake(self):
        # get Microsoft credentials: This code will pop a browser window
        credential = DefaultAzureCredential(
            exclude_interactive_browser_credential=False
        )
        token_bytes = credential.get_token(
            "https://database.windows.net/.default"
        ).token.encode("UTF-16-LE")

        token_struct = struct.pack(
            f"<I{len(token_bytes)}s", len(token_bytes), token_bytes
        )
        connection_string = """Driver={ODBC Driver 17 for SQL Server};
        Server=synanaprod001-ondemand.sql.azuresynapse.net;
        Database=syndb_hidro;Encrypt=yes;TrustServerCertificate=no;
        Connection Timeout=30"""

        self.conn = pyodbc.connect(  # pylint: disable=I1101
            connection_string, attrs_before={1256: token_struct}
        )

    def _load_stations(self, stations_path: str, crs: str):
        """Load the stations into the class

        Args:
            stations_path (str): Path to the stations shape file.
            crs (str): CRS as EPSG string
        """
        # Read the stations file
        stations = gpd.read_file(
            stations_path,
            # engine="pyogrio",
            # use_arrow=False,
        ).set_crs(crs)

        stations["codigo"] = stations["codigo"].astype("int")
        stations["cobacia"] = stations["cobacia"].astype("str")

        # filter the stations by ANA and overall period
        stations = stations[stations["respon"] == "ANA"]
        stations["period"] = stations["anofim"] - stations["anoini"]
        stations = stations[stations["period"] >= 20]
        stations = stations[stations["anofim"] >= 2000]

        self.stations = stations
        self.stations = self.stations.drop(
            index=self.stations.query("codigo == 86950000").index[0]
        )

    def _load_reaches(self, reaches_path: str, crs: str):
        """_summary_

        Args:
            reaches_path (str): _description_
            crs (str): _description_
        """
        self.reaches = gpd.read_file(
            reaches_path,
            engine="pyogrio",
            use_arrow=True,
        ).to_crs(crs)

        # Create a linewidth for the rivers, through the log of areamont
        self.reaches["nuareamont_log"] = np.log10(self.reaches["nuareamont"] + 1)
        self.reaches["linewidth"] = (
            2 * self.reaches["nuareamont_log"] / self.reaches["nuareamont_log"].max()
        )

        # cast cobacia and cocursodag as string
        self.reaches["cobacia"] = self.reaches["cobacia"].astype("str")
        self.reaches["cocursodag"] = self.reaches["cocursodag"].astype("str")

    def _load_watersheds(self, watersheds_path: str, crs: str):
        """_summary_

        Args:
            watersheds_path (str): _description_
            crs (str): _description_
        """
        self.watersheds = gpd.read_file(
            watersheds_path,
            engine="pyogrio",
            use_arrow=True,
        ).to_crs(crs)

        # cast cobacia and cocursodag as string
        self.reaches["cobacia"] = self.reaches["cobacia"].astype("str")
        self.reaches["cocursodag"] = self.reaches["cocursodag"].astype("str")

    def _load_municipalities(self, municipalities_path: str, crs: str):
        """_summary_

        Args:
            municipalities_path (str): _description_
            crs (str): _description_
        """
        self.muns = gpd.read_file(
            municipalities_path, engine="pyogrio", use_arrow=True
        ).set_crs(crs)

    def _load_disasters(self, disasters_path: str):
        self.disasters = pd.read_csv(disasters_path, delimiter=";", low_memory=False)
        self.disasters["data"] = pd.to_datetime(
            self.disasters["data"], format="%d/%m/%Y"
        )

    ###### Private Functions ######
    def _load_urban_area(self, urban_areas_path: str, crs: str):
        """_summary_

        Args:
            urban_areas_path (str): _description_
            crs (str): _description_
        """
        self.uas = UrbanAreas(urban_areas_path, crs=crs)

    def _plot_reaches(self, ax: plt.Axes, **kwargs):
        """_summary_

        Args:
            ax (plt.Axes): _description_
        """

        # for speed reasons, let's filter just reaches within the viewport
        xmin, xmax, ymin, ymax = ax.axis()
        reaches = self.reaches.cx[xmin:xmax, ymin:ymax]
        reaches.plot(ax=ax, linewidth=reaches["linewidth"], **kwargs)

    def _plot_stations(self, ax: plt.Axes, stype: str, codes: bool, zorder: float):

        # first, let's plot all the stations
        # for speed reasons, let's filter just reaches within the viewport
        xmin, xmax, ymin, ymax = ax.axis()
        stations = self.stations.cx[xmin:xmax, ymin:ymax]

        if len(stations) > 0:
            stations.plot(ax=ax, zorder=zorder - 0.1, color="gray")

        if len(self.data[f"{stype}_stations"]) == 0:
            return

        # set the marker according to the stype (down or upstream)
        marker = "^" if stype == "up" else "v"

        self.data[f"{stype}_stations"].plot(
            ax=ax, color="black", zorder=zorder, marker=marker, markersize=60
        )
        self.data[f"selected_{stype}_stations"].plot(
            ax=ax, color="red", zorder=zorder + 0.1, marker=marker, markersize=60
        )

        if codes:
            texts = []
            for _, row in self.data[f"selected_{stype}_stations"].iterrows():
                # get station title
                t = ax.text(
                    x=row.geometry_st.x + 0.02,
                    y=row.geometry_st.y + 0.02,
                    s=str(int(row["codigo"])),
                    zorder=101,
                    # fontweight='bold',
                    fontsize=11,
                )
                # t.set_bbox(dict(facecolor="white", alpha=0.6, edgecolor="white"))
                texts.append(t)

            adjust_text(texts, ax=ax, expand_axes=True, ensure_inside_axes=True)

    def _get_upstream_ua_(
        self,
        buffer: float = 1e-2,
    ) -> Tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:
        """Get reaches and watersheds upstream the urban area

        Args:
            buffer (float, optional): _description_. Defaults to 1e-3.

        Returns:
            Tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]: _description_
        """

        if self.ua is None:
            print("No city selected. Use `select_urban_area` first.")
            return

        self.data["ua_reaches"] = Otto.get_touching(
            self.reaches, self.ua.df, buffer=buffer, auto_increase=True
        )

        self.data["ua_upstream_sheds"] = Otto.get_combined_upstream(
            self.watersheds, self.data["ua_reaches"]
        )
        self.data["ua_upstream_reaches"] = Otto.get_combined_upstream(
            self.reaches, self.data["ua_reaches"]
        )

    def _get_downstream_ua_(self):
        downstream = gpd.GeoDataFrame()
        df = self.data["ua_reaches"].copy()
        df = df.sort_values(["cocursodag", "cobacia"], ascending=False)

        for _, row in df.iterrows():
            downs = Otto.get_downstream(self.reaches, row["cobacia"])
            downstream = pd.concat([downstream, downs], axis=0)

            df = df[~df["cobacia"].isin(downstream["cobacia"])]

            if len(df) == 0:
                break

        self.data["ua_downstream_reaches"] = downstream.drop_duplicates()

    def _get_upstream_stations_(self):

        if "ua_upstream_reaches" not in self.data:
            s = """ua_upstream_reaches is not populated.
                Run `select_urban_area` again to correct it."""
            raise ValueError(s)

        upstream_reaches = self.data["ua_upstream_reaches"]

        if len(upstream_reaches) > 0:
            up_stations = upstream_reaches.set_index("cobacia").join(
                self.stations.set_index("cobacia"), how="left", rsuffix="_st"
            )
            up_stations = up_stations.dropna(subset="codigo").set_geometry(
                "geometry_st"
            )
        else:
            up_stations = gpd.GeoDataFrame()

        self.data["up_stations"] = up_stations

        # now, let's remove the stations upstream other stations
        main_stations = gpd.GeoDataFrame()
        if len(up_stations) > 0:
            stations = up_stations.reset_index(drop=False).copy()
            stations = stations.sort_values(["cocursodag", "cobacia"])

            while len(stations) > 0:

                # get the first stations and save it to the main stations
                row = stations.iloc[[0]]
                main_stations = pd.concat([main_stations, row])

                row = row.iloc[0]

                # erase all stations upstream this station (including this one)
                ups = Otto.get_upstream(stations, row["cobacia"], row["cocursodag"])
                stations = stations[~stations["cobacia"].isin(ups["cobacia"])]

            main_stations.set_geometry("geometry_st").set_crs(self.crs)

        self.data["selected_up_stations"] = main_stations

    def _get_downstream_stations_(self):
        down_reaches = self.data["ua_downstream_reaches"]

        if len(down_reaches) > 0:
            down_stations = down_reaches.set_index("cobacia").join(
                self.stations.set_index("cobacia"), how="left", rsuffix="_st"
            )
            down_stations = (
                down_stations.dropna(subset="codigo")
                .set_geometry("geometry_st")
                .set_crs(self.crs)
            )
        else:
            down_stations = gpd.GeoDataFrame()

        self.data["down_stations"] = down_stations

        if len(down_stations) > 0:
            down_stations = down_stations.reset_index(drop=False)
            down_stations["cobacia"] = down_stations["cobacia"].astype("str")
            down_stations["cocursodag"] = down_stations["cocursodag"].astype("str")

            self.data["selected_down_stations"] = (
                down_stations.sort_values(["cocursodag", "cobacia"])
                .groupby("cocursodag")
                .last()
                .set_crs(self.crs)
            )
        else:
            self.data["selected_down_stations"] = gpd.GeoDataFrame()

    def _set_axis_lims(self, ax: plt.Axes, data: List[gpd.GeoDataFrame]):

        data = [d for d in data if len(d) > 0]
        for d in data:
            d["geometry"] = d[d.geometry.name]
            d.set_geometry("geometry", inplace=True)

        data = pd.concat(data)
        xmin, ymin, xmax, ymax = data.buffer(0.1).total_bounds
        ax.set_xlim([xmin, xmax])
        ax.set_ylim([ymin, ymax])

    ###### Public Functions ######
    def select_urban_area(
        self, city_name: str, area_factor: float = 0.5, figsize: tuple = (1.2, 1)
    ):
        """_summary_

        Args:
            city_name (str): _description_
            area_factor (float): _description_
            figsize (tuple, optional): _description_. Defaults to (1.2, 1).
        """
        # select the city
        self.ua = self.uas.get_urban_area(city_name, area_factor, figsize)

        # get municipality limits
        self.mun = self.muns[self.muns["CD_MUN"] == self.ua.cd_mun].copy()

        # reset the data
        self.data = {}

        # start filling the reaches and watersheds upstream the ua
        print(f"Selecting reaches upstream {city_name}")
        self._get_upstream_ua_()

        # print("Selecting upstream stations")
        self._get_upstream_stations_()

        # select downstream reaches and stations
        self._get_downstream_ua_()
        self._get_downstream_stations_()

    def plot_urban_area(self, ax: plt.Axes):
        """_summary_

        Args:
            ax (plt.Axes): _description_
        """
        if self.ua is None:
            print("No city selected. Use `select_urban_area` first.")
            return

        self.ua.plot(ax=ax, facecolor="none", edgecolor="orange", linewidth=2)

        # freeze viewport limits
        ax.autoscale(False)

        self._plot_reaches(ax=ax)

        cx.add_basemap(
            ax=ax, crs=self.crs, source=cx.providers.Esri.WorldImagery, zorder=-3
        )

    def plot_municipality(self, ax: plt.Axes, stations: bool = False):
        """_summary_

        Args:
            ax (plt.Axes): _description_
        """
        if self.ua is None:
            print("No city selected. Use `select_urban_area` first.")
            return

        # plot minicipality limits
        self.mun.plot(ax=ax, edgecolor="green", linewidth=2, facecolor="none", zorder=0)

        # plot the stations
        if stations:
            data = [
                self.data[d] for d in ["selected_up_stations", "selected_down_stations"]
            ] + [self.mun]

            self._set_axis_lims(ax=ax, data=data)
            self._plot_stations(ax=ax, stype="up", codes=True, zorder=10)
            self._plot_stations(ax=ax, stype="down", codes=True, zorder=10)

        # Freeze viewport limits
        ax.autoscale(False)

        # plot the urban area
        self.ua.plot(ax=ax, facecolor="orange", zorder=-2)

        # plot river reaches
        self._plot_reaches(ax=ax, zorder=-1)

        # plot a basemap
        cx.add_basemap(
            ax=ax,
            crs=self.crs,
            source=cx.providers.CartoDB.PositronNoLabels,
            zorder=-100,
        )

        ax.set_title("Município")

    def plot_context(self, ax: plt.Axes):
        """_summary_

        Args:
            ax (plt.Axes): _description_
        """

        # first plot the UA and the municipality
        self.ua.df.plot(ax=ax, facecolor="orange", zorder=0)
        self.mun.plot(
            ax=ax, facecolor="none", alpha=1, edgecolor="green", zorder=5, linewidth=2.0
        )

        # then, plot the upstream watersheds with an alpha value
        if len(self.data["ua_upstream_sheds"]) > 0:
            self.data["ua_upstream_sheds"].plot(ax=ax, zorder=-2, alpha=0.2)

        # finally, plot downstream
        downs = self.data["ua_downstream_reaches"]
        if len(downs) > 0:
            downs.plot(ax=ax, zorder=-1, edgecolor="blue", linewidth=downs["linewidth"])

        # this is the overall viewport, now we can freeze it
        ax.autoscale(False)

        # ... and plot the river reaches
        self._plot_reaches(ax=ax, zorder=-1)

        # let's plot the ua_reaches with another color
        if len(self.data["ua_reaches"]) > 0:
            self.data["ua_reaches"].plot(
                ax=ax,
                edgecolor="blue",
                zorder=2,
                linewidth=self.data["ua_reaches"]["linewidth"],
            )

        # plot the stations
        self._plot_stations(ax=ax, stype="up", codes=True, zorder=10)
        self._plot_stations(ax=ax, stype="down", codes=True, zorder=10)

        ax.set_title("Visão Geral")

        # cx.add_basemap(
        #     ax=ax,
        #     crs=self.crs,
        #     source=cx.providers.Esri.WorldTopoMap,
        #     zorder=-100,
        # )

    def stations_table(self, stype: str, as_html: bool = False):
        """Return a table with the stations up- or down-stream

        Args:
            stype (str): Group of stations 'up' or 'down'
            as_html (bool, optional): Wether to return as HTML. Defaults to False.

        Returns:
            _type_: Stations table
        """
        stations = self.data[f"{stype}_stations"].copy()

        if len(stations) == 0:
            if as_html:
                return "<h3>Não foram encontradas estações nesta seção</h3>"
            else:
                return stations

        selected = self.data[f"selected_{stype}_stations"].copy()

        for column in ["codigo", "anoini", "anofim", "period"]:
            stations[column] = stations[column].astype("int")

        stations["nuareamont"] = stations["nuareamont"].round(2)
        stations = stations[
            ["codigo", "rio", "nuareamont", "anoini", "anofim", "period", "emoper"]
        ].reset_index(
            drop=False
        )  # .set_index('codigo')
        stations = stations.rename(columns=HydrologyReport.columns_rename).set_index(
            "Código"
        )
        stations["Selecionada"] = ""
        stations.loc[selected["codigo"].astype("int"), "Selecionada"] = "X"

        stations = stations.reset_index()
        if as_html:
            return build_table(stations, "blue_light")
        else:
            return stations

    def get_discharge(self, station_code: int) -> pd.DataFrame:
        """Get the daily discharge values, in m3/s, for a specific station

        Args:
            station_code (int): HIDRO code of the station

        Returns:
            DataFrame: DataFrame with date/values
        """
        query = f"SELECT * FROM hidro.pivotvazoes WHERE EstacaoCodigo = {station_code}"
        rows = self.conn.execute(query).fetchall()

        # convert the rows to a dataframe
        data = pd.DataFrame.from_records(
            rows,
            columns=[
                "id",
                "StationId",
                "QualityLevel",
                "Date",
                "Hour",
                "DailyMean",
                "DischargeHour",
                "Month",
                "Year",
                "Discharge",
                "Day",
                "DateTime",
            ],
            index="id",
        )

        data["DateTime"] = pd.to_datetime(data["DateTime"])

        # now, we are getting the higher quality level for each date
        keys = data[["DateTime", "QualityLevel"]].groupby("DateTime").max()
        keys = keys.reset_index(drop=False).set_index(["DateTime", "QualityLevel"])

        data = data.set_index(["DateTime", "QualityLevel"])
        data = data.loc[keys.index].reset_index(drop=False)

        data = data.set_index("DateTime", drop=True).sort_index()
        drop_columns = [
            "Hour",
            "Date",
            "StationId",
            "QualityLevel",
            "DischargeHour",
            "DailyMean",
        ]
        data = data.drop(columns=drop_columns)
        numeric_columns = ["Day", "Month", "Year", "Discharge"]
        data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric)
        data["Discharge"] = data["Discharge"].round(2)

        # keep just valid values
        data = data.dropna()
        data = data[~pd.isna(data.index)]  # pylint: disable=E1130

        # fill up the Hydrological Year field
        if self.ua.uf in self.hydrological_year:
            month = self.hydrological_year[self.ua.uf]
        else:
            month = self.hydrological_year["default"]

        f = partial(self.get_hydrological_year, month=month)
        data["Ano Hidro"] = data.index.map(f)

        return data

    def calc_return_times(self, station_code: int, distrs: List[str] = None) -> Tuple:
        """Calculate the Return Times for the maximum Discharge values in each hydrological year

        Args:
            station_code (int): Station code
            distrs (List[str], optional): List of scipy distributions.
            If None, defaults to gumbel and lognormal.
            Defaults to False.

        Returns:
            Tuple: _description_
        """
        if distrs is None:
            distrs = HydrologyReport.default_distrs

        data = self.get_discharge(station_code)
        maximum = data.groupby(by="Ano Hidro").max()[["Discharge"]]
        maximum = maximum.reset_index().set_index(["Ano Hidro", "Discharge"])
        maximum = maximum.join(
            data.reset_index().set_index(["Ano Hidro", "Discharge"]), how="left"
        )
        maximum = maximum.reset_index(drop=False)
        maximum = maximum.sort_values(by="Discharge", ascending=False)
        maximum = maximum.drop(columns=["Month", "Year", "Day"])

        # get the number of distributions to fit
        n = len(distrs)

        # create the plot canvas
        original_backend = plt.get_backend()
        plt.switch_backend("agg")
        fig, axs = plt.subplots(n, 1, figsize=(5, n * 6))

        for ax, distr in zip(axs, distrs):

            # Fit the distribution
            distribution = getattr(stats, distr)
            args = distribution.fit(maximum["Discharge"])

            # plot the corresponding chart
            ax.hist(maximum["Discharge"], bins=10, density=True)
            min_x = distribution.ppf(0.0001, *args)
            max_x = distribution.ppf(0.9999, *args)
            x = np.linspace(min_x, max_x, 1000)
            ax.plot(x, distribution.pdf(x, *args), "r-", lw=2, label=f"Fitted {distr}")
            ax.legend()
            ax.set_title(f"Distribuição {distr}")

            # add the RT column
            column_name = f"TR {distr}"
            maximum[column_name] = round(
                maximum["Discharge"].apply(
                    HydrologyReport.recurring_time, args=(distribution, *args)
                ),
                2,
            )

        # Switch back to the original backend
        plt.switch_backend(original_backend)

        return maximum, fig

    def plot_report_map(self):
        """Plot the map figure for the report

        Returns:
            plt.figure: Matplotlib figure
        """
        # create the plot canvas
        original_backend = plt.get_backend()
        plt.switch_backend("agg")

        # First, let's create the maps
        mapfig, axs = plt.subplots(1, 2, figsize=(14, 10))
        # plot the context
        ax = axs[0]
        self.plot_context(ax=ax)

        # plot the municipality
        ax = axs[1]
        self.plot_municipality(ax=ax, stations=True)

        # Switch back to the original backend
        plt.switch_backend(original_backend)

        return mapfig

    def combined_stations(self):
        """Get a combined table with all the stations"""
        stations = pd.DataFrame()
        for stype in ["up", "down"]:
            aux_df = self.stations_table(stype)
            aux_df["Position"] = stype
            stations = pd.concat([stations, aux_df], axis=0)
        return stations

    def disasters_table(self, as_html: bool = False, query: Optional[str] = None):
        """Return the disasters table"""

        # filter the desired municipality
        disasters = self.disasters.query(f"ibge == {self.ua.cd_mun}")

        # if an additional query is passed, just apply it
        if query is not None:
            disasters = disasters.query(query)

        disasters = disasters[
            [
                "data",
                "obitos",
                "feridos",
                "total_danos_humanos",
                "total_danos_materiais",
                "descricao_tipologia",
            ]
        ].sort_values("data", ascending=False)

        if as_html:
            return build_table(disasters, "blue_light")
        else:
            return disasters

    def plot_disaster_graph(
        self, ax: plt.Axes, date: Any, station: int, window: int = 30
    ):
        """Plot the discharge graph for a specific disaster date and station"""

        # convert date to timestamp
        date = timestamp_date(date)

        # get the disaster
        disasters = self.disasters_table(query="grupo_de_desastre == 'Hidrológico'")
        disasters = disasters.set_index("data")
        disaster = disasters.loc[date]

        # Get the discharge
        q = self.get_discharge(station)
        if date in q.index:
            hydro_year = q.loc[date]["Ano Hidro"]
            q_subset = q.query(f"`Ano Hidro` == '{hydro_year}'")

            # Plot discharge
            q_subset["Discharge"].plot(ax=ax, label="Vazão")

            # Plot the disaster line

            ax.autoscale(False)
            xmin, xmax, ymin, ymax = ax.axis()
            ax.vlines(
                x=date,
                ymin=ymin,
                ymax=ymax,
                color="red",
                linestyle="--",
                label=disaster["descricao_tipologia"],
            )

            # Plot disaster fill
            disaster_start = date - relativedelta(days=int(window / 2))
            disaster_end = date + relativedelta(days=int(window / 2))
            ax.fill_between(
                x=[disaster_start, disaster_end],
                y1=ymin,
                y2=ymax,
                color="red",
                alpha=0.2,
            )

            # Plot quantiles
            q5 = q["Discharge"].quantile(0.95)
            q95 = q["Discharge"].quantile(0.05)
            ax.hlines(
                y=q5,
                xmin=xmin,
                xmax=xmax,
                color="orange",
                linewidth=1.5,
                linestyle=":",
                label="Q5",
            )
            ax.hlines(
                y=q95,
                xmin=xmin,
                xmax=xmax,
                color="green",
                linewidth=1.5,
                linestyle=":",
                label="Q95",
            )

            # in the case the graph is displayed, plot the legend
            ax.legend()
        else:
            hydro_year = ""

        # Adjust legends
        ax.set_ylabel("Vazão m³/s")
        ax.set_xlabel("")

        # Adjust the title
        title = f"Ano hidrológico: {hydro_year}\n"
        title += f"Data do desastre ({disaster['descricao_tipologia']}): "
        title += f"{str(disaster.name)[:10]}"
        ax.set_title(title)

    def plot_disasters_charts(self, station: int):
        """Plot charts for all the disasters given one station"""
        # select only hydrological disasters
        disasters = self.disasters_table(query="grupo_de_desastre == 'Hidrológico'")

        # return if no disasters are found in the municipality
        if len(disasters) == 0:
            return

        # prepare the canvas
        cols = 2
        rows = len(disasters) // 2 + len(disasters) % 2

        fig, axs = plt.subplots(
            rows, cols, figsize=(15, rows * 6), gridspec_kw={"hspace": 0.5}
        )
        axs = axs.reshape(-1)

        for i, date in enumerate(disasters["data"]):
            self.plot_disaster_graph(axs[i], date, station)

        fig.suptitle(f"Desastres para estação {station}")
        return fig

    def create_report(self, out_dir: str, create_subfolder: bool = True):
        """Create the Report"""

        # Section 1 map figure
        mapfig = self.plot_report_map()

        # Section 2 - General Info
        info_data = {
            "Município": self.ua.name,
            "Estado": self.ua.uf,
            "Área": str(self.mun["AREA_KM2"].iloc[0]) + " km²",
            "Área urbana": str(self.ua.area) + " km²",
        }
        info_df = pd.DataFrame(info_data, index=[""])

        # Section 3 - Disasters Info
        disasters = {
            "hydro": self.disasters_table(
                as_html=True, query="grupo_de_desastre == 'Hidrológico'"
            ),
            "complete": self.disasters_table(as_html=True),
        }

        # Section 4 - Stations List
        # loop through the stations to create the
        # hydrology sections and save to the stations dictionary
        stations_dict = {}
        for codigo in self.selected_stations:
            table, fig = self.calc_return_times(codigo)
            disasters_fig = self.plot_disasters_charts(codigo)
            stations_dict[codigo] = {
                "df": table,
                "hydrology_table": build_table(
                    table,
                    color="blue_light",
                    width_dict=["20%", "20%", "25%", "18%", "18%"],
                    text_align="center",
                ),
                "hydrology_figure": fig2base64(fig),
                "disasters_figure": fig2base64(disasters_fig),
                "fig": fig,
            }

        # Create a Jinja Environment
        env = Environment(loader=FileSystemLoader("./templates"))
        template = env.get_template("report1.html")

        jinja_data = {
            "place": self.ua.name + " / " + self.ua.uf,
            "upstream_stations": self.stations_table(stype="up", as_html=True),
            "downstream_stations": self.stations_table(stype="down", as_html=True),
            "png_map": fig2base64(mapfig),
            "General_Info": info_df.to_html(),
            "stations": stations_dict,
            "disasters": disasters,
            # "Disasters_Hidro": self.disasters_table(as_html=True),
            # "Disasters_Complete": ,
        }

        # Render the template with your data
        html_output = template.render(jinja_data)

        # Write the HTML output to a file
        folder = self.ua.get_folder(out_dir)
        fname = f"Report_{folder.stem}.html"
        if not create_subfolder:
            fname = folder.with_name(fname)
        else:
            folder.mkdir(exist_ok=True, parents=True)
            fname = folder / fname

            # if create_subfolder, save the tables and images separately
            mapfig.savefig(folder / "context_map.png")

            stations = self.combined_stations()
            stations.to_csv(folder / "stations.csv")
            info_df.to_csv(folder / "general_info.csv")

            # one for each selected station
            for station, values in stations_dict.items():
                table = values["df"]
                fig = values["fig"]

                table.to_csv(folder / f"table_{station}.csv")
                fig.savefig(folder / f"fig_{station}.png")

        # save the report
        with open(fname, "w", encoding="utf-8") as f:
            f.write(html_output)

        # Once the report is saved, release the figs
        plt.close("all")
